{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import datetime\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "import smart_open\n",
    "from string import punctuation\n",
    "stop_words = stopwords.words('english')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Lambda\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,Callback\n",
    "from tensorflow.keras.layers import Input, Bidirectional, LSTM, dot, Flatten, Dense, Reshape, add, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = gensim.models.KeyedVectors.load_word2vec_format('C:\\\\Users\\\\Suraj\\\\GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning\n",
    "\n",
    "\n",
    "SPECIAL_TOKENS = {\n",
    "    'quoted': 'quoted_item',\n",
    "    'non-ascii': 'non_ascii_word',\n",
    "    'undefined': 'something'\n",
    "}\n",
    "\n",
    "\n",
    "def clean(text, stem_words=True):\n",
    "\n",
    "    \n",
    "    if pd.isnull(text):\n",
    "        return ''\n",
    "\n",
    "    if type(text) != str or text=='':\n",
    "        return ''\n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub(\"\\'s\", \" \", text) \n",
    "    text = re.sub(\" whats \", \" what is \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(\"can't\", \"can not\", text)\n",
    "    text = re.sub(\"n't\", \" not \", text)\n",
    "    text = re.sub(\"i'm\", \"i am\", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"\\'re\", \" are \", text)\n",
    "    text = re.sub(\"\\'d\", \" would \", text)\n",
    "    text = re.sub(\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(\"e\\.g\\.\", \" eg \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"b\\.g\\.\", \" bg \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"(\\d+)(kK)\", \" \\g<1>000 \", text)\n",
    "    text = re.sub(\"e-mail\", \" email \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"(the[\\s]+|The[\\s]+)?U\\.S\\.A\\.\", \" America \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"(the[\\s]+|The[\\s]+)?United State(s)?\", \" America \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"\\(s\\)\", \" \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"[c-fC-F]\\:\\/\", \" disk \", text)\n",
    "    text = re.sub('(?<=[0-9])\\,(?=[0-9])', \"\", text)\n",
    "    text = re.sub('\\$', \" dollar \", text)\n",
    "    text = re.sub('\\%', \" percent \", text)\n",
    "    text = re.sub('\\&', \" and \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r'\\d+', '',text)\n",
    "    text = re.sub('(\\\\b[A-Za-z] \\\\b|\\\\b [A-Za-z]\\\\b)', '', text)\n",
    "    text = text.replace(\"?\",\"\")\n",
    "    text = text.replace(\"(\",\"\")\n",
    "    text = text.replace(\")\",\"\")\n",
    "    text = text.replace('\"',\"\")\n",
    "    text = text.replace(\",\",\"\")\n",
    "    text = text.replace(\"#\",\"\")   \n",
    "    text = text.replace(\"-\",\"\")    \n",
    "    text = text.replace(\"..\",\"\")\n",
    "    text = text.replace(\"/\",\"\")\n",
    "    text = text.replace(\"\\\\\",\"\")\n",
    "    text = text.replace(\":\",\"\")\n",
    "    text = text.replace(\"the\",\"\") \n",
    "        \n",
    "    text = text.split()\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['question1'] = df['question1'].apply(clean)\n",
    "df['question2'] = df['question2'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[what, is, step, by, step, guide, to, invest, ...</td>\n",
       "      <td>[what, is, step, by, step, guide, to, invest, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[what, is, story, of, kohinoor, kohinoor, diam...</td>\n",
       "      <td>[what, would, happen, if, indian, government, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>[how, can, increase, speed, of, my, internet, ...</td>\n",
       "      <td>[how, can, internet, speed, be, increased, by,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>[why, am, mentally, very, lonely, how, can, so...</td>\n",
       "      <td>[find, remainder, when, [math]^{}[math], is, d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>[which, one, dissolve, in, water, quikly, suga...</td>\n",
       "      <td>[which, fish, would, survive, in, salt, water]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  [what, is, step, by, step, guide, to, invest, ...   \n",
       "1   1     3     4  [what, is, story, of, kohinoor, kohinoor, diam...   \n",
       "2   2     5     6  [how, can, increase, speed, of, my, internet, ...   \n",
       "3   3     7     8  [why, am, mentally, very, lonely, how, can, so...   \n",
       "4   4     9    10  [which, one, dissolve, in, water, quikly, suga...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  [what, is, step, by, step, guide, to, invest, ...             0  \n",
       "1  [what, would, happen, if, indian, government, ...             0  \n",
       "2  [how, can, internet, speed, be, increased, by,...             0  \n",
       "3  [find, remainder, when, [math]^{}[math], is, d...             0  \n",
       "4     [which, fish, would, survive, in, salt, water]             0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = dict()\n",
    "inverse_vocabulary = ['<unk>']\n",
    "questions_cols = ['question1', 'question2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in df.iterrows():\n",
    "    # Iterate through the text of both questions of the row\n",
    "    for question in questions_cols:\n",
    "        q2n = []  # q2n -> question numbers representation\n",
    "        for word in row[question]:\n",
    "            # Check for unwanted words\n",
    "            if word in stop_words and word not in word2vec.vocab:\n",
    "                continue\n",
    "            if word not in vocabulary:\n",
    "                vocabulary[word] = len(inverse_vocabulary)\n",
    "                q2n.append(len(inverse_vocabulary))\n",
    "                inverse_vocabulary.append(word)\n",
    "            else:\n",
    "                q2n.append(vocabulary[word])\n",
    "        df.at[index, question] = q2n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'what': 1,\n",
       " 'is': 2,\n",
       " 'step': 3,\n",
       " 'by': 4,\n",
       " 'guide': 5,\n",
       " 'invest': 6,\n",
       " 'in': 7,\n",
       " 'share': 8,\n",
       " 'market': 9,\n",
       " 'india': 10,\n",
       " 'story': 11,\n",
       " 'kohinoor': 12,\n",
       " 'diamond': 13,\n",
       " 'would': 14,\n",
       " 'happen': 15,\n",
       " 'if': 16,\n",
       " 'indian': 17,\n",
       " 'government': 18,\n",
       " 'stole': 19,\n",
       " 'back': 20,\n",
       " 'how': 21,\n",
       " 'can': 22,\n",
       " 'increase': 23,\n",
       " 'speed': 24,\n",
       " 'my': 25,\n",
       " 'internet': 26,\n",
       " 'connection': 27,\n",
       " 'while': 28,\n",
       " 'using': 29,\n",
       " 'vpn': 30,\n",
       " 'be': 31,\n",
       " 'increased': 32,\n",
       " 'hacking': 33,\n",
       " 'through': 34,\n",
       " 'dns': 35,\n",
       " 'why': 36,\n",
       " 'am': 37,\n",
       " 'mentally': 38,\n",
       " 'very': 39,\n",
       " 'lonely': 40,\n",
       " 'solve': 41,\n",
       " 'it': 42,\n",
       " 'find': 43,\n",
       " 'remainder': 44,\n",
       " 'when': 45,\n",
       " '[math]^{}[math]': 46,\n",
       " 'divided': 47,\n",
       " 'which': 48,\n",
       " 'one': 49,\n",
       " 'dissolve': 50,\n",
       " 'water': 51,\n",
       " 'quikly': 52,\n",
       " 'sugar': 53,\n",
       " 'salt': 54,\n",
       " 'methane': 55,\n",
       " 'carbon': 56,\n",
       " 'di': 57,\n",
       " 'oxide': 58,\n",
       " 'fish': 59,\n",
       " 'survive': 60,\n",
       " 'astrology': 61,\n",
       " 'capricorn': 62,\n",
       " 'sun': 63,\n",
       " 'cap': 64,\n",
       " 'moon': 65,\n",
       " 'rising.what': 66,\n",
       " 'does': 67,\n",
       " 'that': 68,\n",
       " 'say': 69,\n",
       " 'about': 70,\n",
       " 'me': 71,\n",
       " 'triple': 72,\n",
       " 'ascendant': 73,\n",
       " 'this': 74,\n",
       " 'should': 75,\n",
       " 'buy': 76,\n",
       " 'tiago': 77,\n",
       " 'keeps': 78,\n",
       " 'childern': 79,\n",
       " 'active': 80,\n",
       " 'far': 81,\n",
       " 'from': 82,\n",
       " 'phone': 83,\n",
       " 'video': 84,\n",
       " 'games': 85,\n",
       " 'good': 86,\n",
       " 'geologist': 87,\n",
       " 'do': 88,\n",
       " 'great': 89,\n",
       " 'you': 90,\n",
       " 'use': 91,\n",
       " 'シ': 92,\n",
       " 'instead': 93,\n",
       " 'し': 94,\n",
       " 'motorola': 95,\n",
       " 'company': 96,\n",
       " 'hack': 97,\n",
       " 'charter': 98,\n",
       " 'motorolla': 99,\n",
       " 'dcx': 100,\n",
       " 'for': 101,\n",
       " 'free': 102,\n",
       " 'method': 103,\n",
       " 'separation': 104,\n",
       " 'slits': 105,\n",
       " 'fresnel': 106,\n",
       " 'biprism': 107,\n",
       " 'are': 108,\n",
       " 'some': 109,\n",
       " 'things': 110,\n",
       " 'technicians': 111,\n",
       " 'tell': 112,\n",
       " 'durability': 113,\n",
       " 'reliability': 114,\n",
       " 'laptops': 115,\n",
       " 'its': 116,\n",
       " 'components': 117,\n",
       " 'read': 118,\n",
       " 'youtube': 119,\n",
       " 'comments': 120,\n",
       " 'see': 121,\n",
       " 'all': 122,\n",
       " 'make': 123,\n",
       " 'physics': 124,\n",
       " 'easy': 125,\n",
       " 'learn': 126,\n",
       " 'was': 127,\n",
       " 'your': 128,\n",
       " 'first': 129,\n",
       " 'sexual': 130,\n",
       " 'experience': 131,\n",
       " 'like': 132,\n",
       " 'laws': 133,\n",
       " 'change': 134,\n",
       " 'status': 135,\n",
       " 'student': 136,\n",
       " 'visa': 137,\n",
       " 'green': 138,\n",
       " 'card': 139,\n",
       " 'us': 140,\n",
       " 'y': 141,\n",
       " 'compare': 142,\n",
       " 'immigration': 143,\n",
       " 'canada': 144,\n",
       " 'japan': 145,\n",
       " 'trump': 146,\n",
       " 'presidency': 147,\n",
       " 'mean': 148,\n",
       " 'current': 149,\n",
       " 'international': 150,\n",
       " 'master’students': 151,\n",
       " 'on': 152,\n",
       " 'an': 153,\n",
       " 'will': 154,\n",
       " 'affect': 155,\n",
       " 'students': 156,\n",
       " 'presently': 157,\n",
       " 'or': 158,\n",
       " 'planning': 159,\n",
       " 'study': 160,\n",
       " 'manipulation': 161,\n",
       " 'means': 162,\n",
       " 'girls': 163,\n",
       " 'want': 164,\n",
       " 'friends': 165,\n",
       " 'with': 166,\n",
       " 'guy': 167,\n",
       " 'reject': 168,\n",
       " 'guys': 169,\n",
       " 'feel': 170,\n",
       " 'after': 171,\n",
       " 'rejecting': 172,\n",
       " 'girl': 173,\n",
       " 'so': 174,\n",
       " 'many': 175,\n",
       " 'quora': 176,\n",
       " 'users': 177,\n",
       " 'posting': 178,\n",
       " 'questions': 179,\n",
       " 'readily': 180,\n",
       " 'answered': 181,\n",
       " 'google': 182,\n",
       " 'people': 183,\n",
       " 'ask': 184,\n",
       " 'easily': 185,\n",
       " 'best': 186,\n",
       " 'digital': 187,\n",
       " 'marketing': 188,\n",
       " 'institution': 189,\n",
       " 'banglore': 190,\n",
       " 'institute': 191,\n",
       " 'pune': 192,\n",
       " 'rockets': 193,\n",
       " 'look': 194,\n",
       " 'white': 195,\n",
       " 'boosters': 196,\n",
       " 'painted': 197,\n",
       " 'causing': 198,\n",
       " 'someone': 199,\n",
       " 'jealous': 200,\n",
       " 'avoid': 201,\n",
       " 'being': 202,\n",
       " 'not': 203,\n",
       " 'question': 204,\n",
       " 'much': 205,\n",
       " 'kv': 206,\n",
       " 'hp': 207,\n",
       " 'where': 208,\n",
       " 'conversion': 209,\n",
       " 'chart': 210,\n",
       " 'cc': 211,\n",
       " 'horsepower': 212,\n",
       " 'every': 213,\n",
       " 'time': 214,\n",
       " 'at': 215,\n",
       " 'clock': 216,\n",
       " 'numbers': 217,\n",
       " 'same': 218,\n",
       " 'times': 219,\n",
       " 'day': 220,\n",
       " 'clock’hands': 221,\n",
       " 'overlap': 222,\n",
       " 'tips': 223,\n",
       " 'making': 224,\n",
       " 'job': 225,\n",
       " 'interview': 226,\n",
       " 'process': 227,\n",
       " 'medicines': 228,\n",
       " 'foundation': 229,\n",
       " 'medicine': 230,\n",
       " 'web': 231,\n",
       " 'application': 232,\n",
       " 'framework': 233,\n",
       " 'society': 234,\n",
       " 'place': 235,\n",
       " 'too': 236,\n",
       " 'importance': 237,\n",
       " 'sports': 238,\n",
       " 'contribute': 239,\n",
       " 'way': 240,\n",
       " 'money': 241,\n",
       " 'online': 242,\n",
       " 'prepare': 243,\n",
       " 'ca': 244,\n",
       " 'final': 245,\n",
       " 'law': 246,\n",
       " 'know': 247,\n",
       " 'heshe': 248,\n",
       " 'completely': 249,\n",
       " 'exam': 250,\n",
       " 'thing': 251,\n",
       " 'better': 252,\n",
       " 'despite': 253,\n",
       " 'knowing': 254,\n",
       " 'special': 255,\n",
       " 'cares': 256,\n",
       " 'nose': 257,\n",
       " 'gets': 258,\n",
       " 'stuffy': 259,\n",
       " 'during': 260,\n",
       " 'night': 261,\n",
       " 'keep': 262,\n",
       " 'getting': 263,\n",
       " 'game': 264,\n",
       " 'thrones': 265,\n",
       " 'villain': 266,\n",
       " 'most': 267,\n",
       " 'likely': 268,\n",
       " 'give': 269,\n",
       " 'mercy': 270,\n",
       " 'America': 271,\n",
       " 'still': 272,\n",
       " 'blacklist': 273,\n",
       " 'employment': 274,\n",
       " 'etc.': 275,\n",
       " 'citizens': 276,\n",
       " 'because': 277,\n",
       " 'ir': 278,\n",
       " 'political': 279,\n",
       " 'views': 280,\n",
       " 'average': 281,\n",
       " 'gas': 282,\n",
       " 'molecules': 283,\n",
       " 'determined': 284,\n",
       " 'travel': 285,\n",
       " 'website': 286,\n",
       " 'spain': 287,\n",
       " 'think': 288,\n",
       " 'obama': 289,\n",
       " 'try': 290,\n",
       " 'take': 291,\n",
       " 'guns': 292,\n",
       " 'away': 293,\n",
       " 'has': 294,\n",
       " 're': 295,\n",
       " 'been': 296,\n",
       " 'gun': 297,\n",
       " 'control': 298,\n",
       " 'initiative': 299,\n",
       " 'already': 300,\n",
       " 'own': 301,\n",
       " 'yearold.': 302,\n",
       " 'improve': 303,\n",
       " 'skills': 304,\n",
       " 'become': 305,\n",
       " 'entrepreneur': 306,\n",
       " 'next': 307,\n",
       " 'few': 308,\n",
       " 'years': 309,\n",
       " 'year': 310,\n",
       " 'old': 311,\n",
       " 'guy.': 312,\n",
       " 'billionaire': 313,\n",
       " 'girlfriend': 314,\n",
       " 'asks': 315,\n",
       " 'her': 316,\n",
       " 'boyfriend': 317,\n",
       " 'did': 318,\n",
       " 'choose': 319,\n",
       " 'makes': 320,\n",
       " 'reply': 321,\n",
       " 'said': 322,\n",
       " 'we': 323,\n",
       " 'end': 324,\n",
       " 'she': 325,\n",
       " 'confused': 326,\n",
       " 'feelings': 327,\n",
       " 'me.': 328,\n",
       " 'wished': 329,\n",
       " 'well': 330,\n",
       " 'disconnected.': 331,\n",
       " 'call': 332,\n",
       " 'wants': 333,\n",
       " 'get': 334,\n",
       " 'toger': 335,\n",
       " 'upsc': 336,\n",
       " 'civil': 337,\n",
       " 'service': 338,\n",
       " 'stall': 339,\n",
       " 'aoa': 340,\n",
       " 'wings': 341,\n",
       " 'fully': 342,\n",
       " 'swept': 343,\n",
       " 'aircraft': 344,\n",
       " 'stop': 345,\n",
       " 'variablesweep': 346,\n",
       " 'those': 347,\n",
       " 'slavs': 348,\n",
       " 'squat': 349,\n",
       " 'squats': 350,\n",
       " 'legs': 351,\n",
       " 'thicker': 352,\n",
       " 'expect': 353,\n",
       " 'cognizant': 354,\n",
       " 'confirmation': 355,\n",
       " 'mail': 356,\n",
       " 'month': 357,\n",
       " 'trading': 358,\n",
       " 'kid': 359,\n",
       " 'rebel': 360,\n",
       " 'worth': 361,\n",
       " 'long': 362,\n",
       " 'run': 363,\n",
       " 'bored': 364,\n",
       " 'universities': 365,\n",
       " 'rexnord': 366,\n",
       " 'recruit': 367,\n",
       " 'new': 368,\n",
       " 'grads': 369,\n",
       " 'majors': 370,\n",
       " 'looking': 371,\n",
       " 'foods': 372,\n",
       " 'quickest': 373,\n",
       " 'instagram': 374,\n",
       " 'followers': 375,\n",
       " 'our': 376,\n",
       " 'number': 377,\n",
       " 'darth': 378,\n",
       " 'vader': 379,\n",
       " 'fought': 380,\n",
       " 'maul': 381,\n",
       " 'star': 382,\n",
       " 'wars': 383,\n",
       " 'legends': 384,\n",
       " 'have': 385,\n",
       " 'character': 386,\n",
       " 'limit': 387,\n",
       " 'profile': 388,\n",
       " 'descriptions': 389,\n",
       " 'stages': 390,\n",
       " 'breaking': 391,\n",
       " 'up': 392,\n",
       " 'between': 393,\n",
       " 'couple': 394,\n",
       " 'happens': 395,\n",
       " 'emotionally': 396,\n",
       " 'wher': 397,\n",
       " 'male': 398,\n",
       " 'female': 399,\n",
       " 'who': 400,\n",
       " 'affected': 401,\n",
       " 'more': 402,\n",
       " 'breakup': 403,\n",
       " 'boy': 404,\n",
       " 'examples': 405,\n",
       " 'products': 406,\n",
       " 'crude': 407,\n",
       " 'oil': 408,\n",
       " 'made': 409,\n",
       " 'friends.': 410,\n",
       " 'career': 411,\n",
       " 'launcher': 412,\n",
       " 'rbi': 413,\n",
       " 'grade': 414,\n",
       " 'preparation': 415,\n",
       " 'program': 416,\n",
       " 'blu': 417,\n",
       " 'ray': 418,\n",
       " 'play': 419,\n",
       " 'regular': 420,\n",
       " 'dvd': 421,\n",
       " 'player': 422,\n",
       " 'nd': 423,\n",
       " 'always': 424,\n",
       " 'sad': 425,\n",
       " 'aerodynamically': 426,\n",
       " 'propellor': 427,\n",
       " 'rotates': 428,\n",
       " 'bestmost': 429,\n",
       " 'memorable': 430,\n",
       " 'ever': 431,\n",
       " 'eaten': 432,\n",
       " 'delicious': 433,\n",
       " 'dish': 434,\n",
       " 'gst': 435,\n",
       " 'affects': 436,\n",
       " 'cas': 437,\n",
       " 'tax': 438,\n",
       " 'officers': 439,\n",
       " 'homework': 440,\n",
       " 'difficult': 441,\n",
       " 'into': 442,\n",
       " 'rsi': 443,\n",
       " 'apply': 444,\n",
       " 'programs': 445,\n",
       " 'rising': 446,\n",
       " 'senior': 447,\n",
       " 'israil': 448,\n",
       " 'friend': 449,\n",
       " 'lying': 450,\n",
       " 'his': 451,\n",
       " 'true': 452,\n",
       " 'he': 453,\n",
       " 'secretly': 454,\n",
       " 'attracted': 455,\n",
       " 'rap': 456,\n",
       " 'songs': 457,\n",
       " 'dance': 458,\n",
       " 'suddenly': 459,\n",
       " 'logged': 460,\n",
       " 'off': 461,\n",
       " 'gmail.': 462,\n",
       " 'remember': 463,\n",
       " 'gmail': 464,\n",
       " 'password': 465,\n",
       " 'just': 466,\n",
       " 'realized': 467,\n",
       " 'recovery': 468,\n",
       " 'email': 469,\n",
       " 'no': 470,\n",
       " 'longer': 471,\n",
       " 'alive.': 472,\n",
       " 'email.': 473,\n",
       " 'recover': 474,\n",
       " 'ways': 475,\n",
       " 'french': 476,\n",
       " 'genders': 477,\n",
       " 'download': 478,\n",
       " 'content': 479,\n",
       " 'kickass': 480,\n",
       " 'torrent': 481,\n",
       " 'without': 482,\n",
       " 'registration': 483,\n",
       " 'torrents': 484,\n",
       " 'trustworthy': 485,\n",
       " 'normal': 486,\n",
       " 'dark': 487,\n",
       " 'ring': 488,\n",
       " 'around': 489,\n",
       " 'iris': 490,\n",
       " 'eye': 491,\n",
       " 'causes': 492,\n",
       " 'treated': 493,\n",
       " 'harry': 494,\n",
       " 'potter': 495,\n",
       " 'book': 496,\n",
       " \"'harry\": 497,\n",
       " 'cursed': 498,\n",
       " \"child'\": 499,\n",
       " 'bad': 500,\n",
       " 'by.rowling': 501,\n",
       " 'depressed': 502,\n",
       " 'evening': 503,\n",
       " 'european': 504,\n",
       " 'family': 505,\n",
       " 'office': 506,\n",
       " 'database': 507,\n",
       " 'find.s.': 508,\n",
       " 'java': 509,\n",
       " 'programming': 510,\n",
       " 'language': 511,\n",
       " 'computer': 512,\n",
       " 'important': 513,\n",
       " 'store': 514,\n",
       " 'energy': 515,\n",
       " 'produced': 516,\n",
       " 'lightning': 517,\n",
       " 'possible': 518,\n",
       " 'review': 519,\n",
       " 'performance': 520,\n",
       " 'testing': 521,\n",
       " 'cost': 522,\n",
       " 'privacy': 523,\n",
       " 'as': 524,\n",
       " 'germany': 525,\n",
       " 'come': 526,\n",
       " 'else': 527,\n",
       " 'lost': 528,\n",
       " 'gain': 529,\n",
       " 'any': 530,\n",
       " 'genuinely': 531,\n",
       " 'enjoy': 532,\n",
       " 'salad': 533,\n",
       " 'dressing': 534,\n",
       " 'types': 535,\n",
       " 'immunity': 536,\n",
       " 'different': 537,\n",
       " 'body': 538,\n",
       " 'narcissistic': 539,\n",
       " 'personality': 540,\n",
       " 'disorder': 541,\n",
       " 'speak': 542,\n",
       " 'english': 543,\n",
       " 'fluently': 544,\n",
       " 'helpful': 545,\n",
       " \"quickbooks'\": 546,\n",
       " 'auto': 547,\n",
       " 'data': 548,\n",
       " 'support': 549,\n",
       " 'corrupted': 550,\n",
       " 'files': 551,\n",
       " 'quickbooks': 552,\n",
       " 'customer': 553,\n",
       " 'usa': 554,\n",
       " 'richest': 555,\n",
       " 'gambler': 556,\n",
       " 'reach': 557,\n",
       " 'level': 558,\n",
       " 'fire': 559,\n",
       " 'bullet': 560,\n",
       " 'backward': 561,\n",
       " 'going': 562,\n",
       " 'faster': 563,\n",
       " 'than': 564,\n",
       " 'bullet;': 565,\n",
       " 'backwards': 566,\n",
       " 'bullets': 567,\n",
       " 'sound': 568,\n",
       " 'shot': 569,\n",
       " 'devastation': 570,\n",
       " 'occurs': 571,\n",
       " 'prevent': 572,\n",
       " 'breast': 573,\n",
       " 'cancer': 574,\n",
       " 'preventable': 575,\n",
       " 'log': 576,\n",
       " 'out': 577,\n",
       " 'account': 578,\n",
       " 'telling': 579,\n",
       " 'ip': 580,\n",
       " 'address': 581,\n",
       " 'device': 582,\n",
       " 'name': 583,\n",
       " 'excluding': 584,\n",
       " 'selling': 585,\n",
       " 'purpose': 586,\n",
       " 'life': 587,\n",
       " 'actually': 588,\n",
       " 'bjp': 589,\n",
       " 'strip': 590,\n",
       " 'muslims': 591,\n",
       " 'christians': 592,\n",
       " 'citizenship': 593,\n",
       " 'put': 594,\n",
       " 'm': 595,\n",
       " 'boats': 596,\n",
       " 'rohingya': 597,\n",
       " 'burma': 598,\n",
       " 'burmarohingya': 599,\n",
       " 'model': 600,\n",
       " 'deport': 601,\n",
       " 'illegal': 602,\n",
       " 'bangladeshis': 603,\n",
       " 'right': 604,\n",
       " 'etiquette': 605,\n",
       " 'wishing': 606,\n",
       " 'jehovah': 607,\n",
       " 'witness': 608,\n",
       " 'happy': 609,\n",
       " 'birthday': 610,\n",
       " 'person': 611,\n",
       " 'wish': 612,\n",
       " 'open': 613,\n",
       " 'commercial': 614,\n",
       " 'fm': 615,\n",
       " 'radio': 616,\n",
       " 'station': 617,\n",
       " 'city': 618,\n",
       " 'procedure': 619,\n",
       " 'commercialclip': 620,\n",
       " 'hd': 621,\n",
       " 'zealand.': 622,\n",
       " 'swiss': 623,\n",
       " 'despise': 624,\n",
       " 'asians': 625,\n",
       " 'technical': 626,\n",
       " 'employees': 627,\n",
       " 'sales': 628,\n",
       " 'high': 629,\n",
       " 'salary': 630,\n",
       " 'income': 631,\n",
       " 'jobs': 632,\n",
       " 'field': 633,\n",
       " 'biotechnology': 634,\n",
       " 'paying': 635,\n",
       " 'fresher': 636,\n",
       " 'an.tech': 637,\n",
       " 'height': 638,\n",
       " 'also': 639,\n",
       " 'were': 640,\n",
       " 'major': 641,\n",
       " 'effects': 642,\n",
       " 'cambodia': 643,\n",
       " 'earthquake': 644,\n",
       " 'se': 645,\n",
       " 'kamchatca': 646,\n",
       " 'earthquakes': 647,\n",
       " 'valparaiso': 648,\n",
       " 'difference': 649,\n",
       " 'sincerity': 650,\n",
       " 'fairness': 651,\n",
       " 'honest': 652,\n",
       " 'sincere': 653,\n",
       " 'gaming': 654,\n",
       " 'laptop': 655,\n",
       " 'under': 656,\n",
       " 'inr': 657,\n",
       " 'rs': 658,\n",
       " 'warrior': 659,\n",
       " 'proving': 660,\n",
       " 'grounds': 661,\n",
       " 'part': 662,\n",
       " 'reference': 663,\n",
       " 'class': 664,\n",
       " 'th': 665,\n",
       " 'chemistry': 666,\n",
       " 'cbse': 667,\n",
       " 'board': 668,\n",
       " 'national': 669,\n",
       " 'technology': 670,\n",
       " 'kurukshetra': 671,\n",
       " 'social': 672,\n",
       " 'nitk': 673,\n",
       " 'surathkal': 674,\n",
       " 'karnataka': 675,\n",
       " 'graduating': 676,\n",
       " 'batch': 677,\n",
       " 'lessons': 678,\n",
       " 'juniors': 679,\n",
       " 'before': 680,\n",
       " 'leave': 681,\n",
       " 'romantic': 682,\n",
       " 'movies': 683,\n",
       " 'movie': 684,\n",
       " 'seen': 685,\n",
       " 'nightmare': 686,\n",
       " 'nightmares': 687,\n",
       " 'seem': 688,\n",
       " 'real': 689,\n",
       " 'abstract': 690,\n",
       " 'expressionism': 691,\n",
       " 'painting': 692,\n",
       " 'influences': 693,\n",
       " 'printing': 694,\n",
       " 'work': 695,\n",
       " 'attend': 696,\n",
       " 'caltech': 697,\n",
       " 'jeremy': 698,\n",
       " 'ehrhardt': 699,\n",
       " 'notable': 700,\n",
       " 'folks': 701,\n",
       " 'attended': 702,\n",
       " 'horcrux': 703,\n",
       " 'associate': 704,\n",
       " 'product': 705,\n",
       " 'manager': 706,\n",
       " 'apm': 707,\n",
       " 'early': 708,\n",
       " 'join': 709,\n",
       " 'management': 710,\n",
       " 'rewarding': 711,\n",
       " 'general': 712,\n",
       " 'requirement': 713,\n",
       " 'based': 714,\n",
       " 'software': 715,\n",
       " 'skype': 716,\n",
       " 'busy': 717,\n",
       " 'could': 718,\n",
       " 'android': 719,\n",
       " 'really': 720,\n",
       " 'war': 721,\n",
       " 'pakistan': 722,\n",
       " 'over': 723,\n",
       " 'uri': 724,\n",
       " 'attack': 725,\n",
       " 'nuclear': 726,\n",
       " 'ronald': 727,\n",
       " 'reagan': 728,\n",
       " 'mannerism': 729,\n",
       " 'speech': 730,\n",
       " 'react': 731,\n",
       " 'strategies': 732,\n",
       " 'union': 733,\n",
       " 'confederates': 734,\n",
       " 'possibly': 735,\n",
       " 'defeated': 736,\n",
       " 'forces': 737,\n",
       " 'gettysburg': 738,\n",
       " 'american': 739,\n",
       " 'fiction': 740,\n",
       " 'novel': 741,\n",
       " 'novels': 742,\n",
       " 'forgot': 743,\n",
       " 'recent': 744,\n",
       " 'demonetisation': 745,\n",
       " 'results': 746,\n",
       " 'higher': 747,\n",
       " 'gdp': 748,\n",
       " 'both': 749,\n",
       " 'short': 750,\n",
       " 'heard': 751,\n",
       " 'whatsapp': 752,\n",
       " 'hacked': 753,\n",
       " 'love': 754,\n",
       " 'pity': 755,\n",
       " 'competitive': 756,\n",
       " 'hiring': 757,\n",
       " 'republic': 758,\n",
       " 'bank': 759,\n",
       " 'helps': 760,\n",
       " 'spam': 761,\n",
       " 'ranking': 762,\n",
       " 'adjustment': 763,\n",
       " 'search': 764,\n",
       " 'distribution': 765,\n",
       " 'traffic': 766,\n",
       " 'organic': 767,\n",
       " 'eg': 768,\n",
       " 'vs.': 769,\n",
       " 'rankings': 770,\n",
       " 'page': 771,\n",
       " 'second': 772,\n",
       " 'watch': 773,\n",
       " 'gonulcelen': 774,\n",
       " 'subtitles': 775,\n",
       " 'sarrainodu': 776,\n",
       " 'powerful': 777,\n",
       " 'country': 778,\n",
       " 'world': 779,\n",
       " 'obtain': 780,\n",
       " 'instant': 781,\n",
       " 'ulcer': 782,\n",
       " 'pain': 783,\n",
       " 'relief': 784,\n",
       " 'low': 785,\n",
       " 'heat': 786,\n",
       " 'ice': 787,\n",
       " 'china': 788,\n",
       " 'food': 789,\n",
       " 'chinese': 790,\n",
       " 'taking': 791,\n",
       " 'advantage': 792,\n",
       " 'worse': 793,\n",
       " 'materialistic': 794,\n",
       " 'cry': 795,\n",
       " 'stick': 796,\n",
       " 'tongues': 797,\n",
       " 'pictures': 798,\n",
       " 'teen': 799,\n",
       " 'women': 800,\n",
       " 'allow': 801,\n",
       " 'boyfriends': 802,\n",
       " 'naked': 803,\n",
       " 'age': 804,\n",
       " 'ending': 805,\n",
       " 'depressing': 806,\n",
       " 'winston': 807,\n",
       " 'julia': 808,\n",
       " 'differ': 809,\n",
       " 'similar': 810,\n",
       " 'mindblowing': 811,\n",
       " 'tools': 812,\n",
       " 'exist': 813,\n",
       " 'technologies': 814,\n",
       " 'toothbrush': 815,\n",
       " 'wet': 816,\n",
       " 'dry': 817,\n",
       " 'applying': 818,\n",
       " 'toothpaste': 819,\n",
       " 'cheapest': 820,\n",
       " 'marked': 821,\n",
       " 'needing': 822,\n",
       " 'imrovement': 823,\n",
       " '‘need': 824,\n",
       " 'improve’': 825,\n",
       " 'neutral': 826,\n",
       " 'state': 827,\n",
       " 'buffer': 828,\n",
       " 'declared': 829,\n",
       " 'against': 830,\n",
       " 'each': 831,\n",
       " 'win': 832,\n",
       " 'mineral': 833,\n",
       " 'holds': 834,\n",
       " 'highest': 835,\n",
       " 'electrical': 836,\n",
       " 'charge': 837,\n",
       " 'hold': 838,\n",
       " 'greatest': 839,\n",
       " 'mystery': 840,\n",
       " 'universe': 841,\n",
       " 'alternative': 842,\n",
       " 'machine': 843,\n",
       " 'learning': 844,\n",
       " 'oversample': 845,\n",
       " 'multiclass': 846,\n",
       " 'imbalance': 847,\n",
       " 'set': 848,\n",
       " 'block': 849,\n",
       " 'sanctions': 850,\n",
       " 'un': 851,\n",
       " 'jaishemohammad': 852,\n",
       " 'jem': 853,\n",
       " 'chief': 854,\n",
       " 'masood': 855,\n",
       " 'azhar': 856,\n",
       " 'future': 857,\n",
       " 'budget': 858,\n",
       " 'meaning': 859,\n",
       " 'excessive': 860,\n",
       " 'amounts': 861,\n",
       " 'vitamin': 862,\n",
       " 'cause': 863,\n",
       " 'miscarriage': 864,\n",
       " 'asahi': 865,\n",
       " 'glass': 866,\n",
       " 'pay': 867,\n",
       " 'scale': 868,\n",
       " 'two': 869,\n",
       " 'letter': 870,\n",
       " 'intent': 871,\n",
       " 'recruitment': 872,\n",
       " 'access': 873,\n",
       " 'torbox': 874,\n",
       " 'google.com': 875,\n",
       " 'yakshini': 876,\n",
       " 'mantras': 877,\n",
       " 'yantra': 878,\n",
       " 'mantra': 879,\n",
       " 'six': 880,\n",
       " 'party': 881,\n",
       " 'talks': 882,\n",
       " 'successful': 883,\n",
       " 'course': 884,\n",
       " 'nicmar': 885,\n",
       " 'register': 886,\n",
       " 'domain': 887,\n",
       " 'site': 888,\n",
       " '.an': 889,\n",
       " 'older': 890,\n",
       " 'men': 891,\n",
       " 'young': 892,\n",
       " 'strongest': 893,\n",
       " 'structure': 894,\n",
       " 'shape': 895,\n",
       " 'compression': 896,\n",
       " 'kevlar': 897,\n",
       " 'cord': 898,\n",
       " 'matter': 899,\n",
       " 'humans': 900,\n",
       " 'selfish': 901,\n",
       " 'evil': 902,\n",
       " 'humanity': 903,\n",
       " 'exocytosis': 904,\n",
       " 'endocytosis': 905,\n",
       " 'passive': 906,\n",
       " 'transport': 907,\n",
       " 'cells': 908,\n",
       " 'hair': 909,\n",
       " 'bald': 910,\n",
       " 'head': 911,\n",
       " 'shave': 912,\n",
       " 'n': 913,\n",
       " 'grew': 914,\n",
       " 'intially': 915,\n",
       " 'loose': 916,\n",
       " 'ideal': 917,\n",
       " 'retirement': 918,\n",
       " 'stance': 919,\n",
       " 'possession': 920,\n",
       " 'weapons': 921,\n",
       " 'mass': 922,\n",
       " 'destruction': 923,\n",
       " 'north': 924,\n",
       " 'korea': 925,\n",
       " 'dprk': 926,\n",
       " 'websites': 927,\n",
       " 'escorts': 928,\n",
       " 'escort': 929,\n",
       " 'polo': 930,\n",
       " 'diesel': 931,\n",
       " 'grand': 932,\n",
       " 'petrol': 933,\n",
       " 'diet': 934,\n",
       " 'growing': 935,\n",
       " 'decathlete': 936,\n",
       " 'black': 937,\n",
       " 'hole': 938,\n",
       " 'finite': 939,\n",
       " 'morgan': 940,\n",
       " 'freeman': 941,\n",
       " 'correct': 942,\n",
       " 'says': 943,\n",
       " 'only': 944,\n",
       " 'racism': 945,\n",
       " 'talking': 946,\n",
       " 'quote': 947,\n",
       " 'fab': 948,\n",
       " 'currently': 949,\n",
       " 'offer': 950,\n",
       " 'stock': 951,\n",
       " 'options': 952,\n",
       " 'rsus': 953,\n",
       " 'uber': 954,\n",
       " 'waveclues': 955,\n",
       " 'reviews': 956,\n",
       " 'distribute': 957,\n",
       " 'identical': 958,\n",
       " 'pencils': 959,\n",
       " 'least': 960,\n",
       " 'pencil': 961,\n",
       " 'apples': 962,\n",
       " 'distributed': 963,\n",
       " 'among': 964,\n",
       " 'children': 965,\n",
       " 'such': 966,\n",
       " 'child': 967,\n",
       " 'hire': 968,\n",
       " 'jerry': 969,\n",
       " 'seinfeld': 970,\n",
       " 'hours': 971,\n",
       " 'tape': 972,\n",
       " 'hour': 973,\n",
       " 'presentation': 974,\n",
       " 'days': 975,\n",
       " 'late': 976,\n",
       " 'rabies': 977,\n",
       " 'vaccine': 978,\n",
       " 'nonbite': 979,\n",
       " 'exposure': 980,\n",
       " 'injection': 981,\n",
       " 'dog': 982,\n",
       " 'bite': 983,\n",
       " 'britain': 984,\n",
       " 'ruled': 985,\n",
       " 'standard': 986,\n",
       " 'amount': 987,\n",
       " 'given': 988,\n",
       " 'relocation': 989,\n",
       " 'afraid': 990,\n",
       " 'working': 991,\n",
       " 'everything': 992,\n",
       " 'red': 993,\n",
       " 'keys': 994,\n",
       " 'oitnb': 995,\n",
       " 'season': 996,\n",
       " 'orange': 997,\n",
       " 'lose': 998,\n",
       " 'virginity': 999,\n",
       " 'forgetful': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116885"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['id','qid1','qid2'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3, 4, 3, 5, 6, 7, 8, 9, 7, 10]</td>\n",
       "      <td>[1, 2, 3, 4, 3, 5, 6, 7, 8, 9]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 11, 12, 12, 13]</td>\n",
       "      <td>[1, 14, 15, 16, 17, 18, 19, 12, 12, 13, 20]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[21, 22, 23, 24, 25, 26, 27, 28, 29, 30]</td>\n",
       "      <td>[21, 22, 26, 24, 31, 32, 4, 33, 34, 35]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[36, 37, 38, 39, 40, 21, 22, 41, 42]</td>\n",
       "      <td>[43, 44, 45, 46, 2, 47, 4]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[48, 49, 50, 7, 51, 52, 53, 54, 55, 56, 57, 58]</td>\n",
       "      <td>[48, 59, 14, 60, 7, 54, 51]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         question1  \\\n",
       "0            [1, 2, 3, 4, 3, 5, 6, 7, 8, 9, 7, 10]   \n",
       "1                           [1, 2, 11, 12, 12, 13]   \n",
       "2         [21, 22, 23, 24, 25, 26, 27, 28, 29, 30]   \n",
       "3             [36, 37, 38, 39, 40, 21, 22, 41, 42]   \n",
       "4  [48, 49, 50, 7, 51, 52, 53, 54, 55, 56, 57, 58]   \n",
       "\n",
       "                                     question2  is_duplicate  \n",
       "0               [1, 2, 3, 4, 3, 5, 6, 7, 8, 9]             0  \n",
       "1  [1, 14, 15, 16, 17, 18, 19, 12, 12, 13, 20]             0  \n",
       "2      [21, 22, 26, 24, 31, 32, 4, 33, 34, 35]             0  \n",
       "3                   [43, 44, 45, 46, 2, 47, 4]             0  \n",
       "4                  [48, 59, 14, 60, 7, 54, 51]             0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "embeddings = 1 * np.random.randn(len(vocabulary) + 1, embedding_dim)\n",
    "embeddings[0] = 0\n",
    "# Build the embedding matrix\n",
    "for word, index in vocabulary.items():\n",
    "    if word in word2vec.vocab:\n",
    "        embeddings[index] = word2vec.word_vec(word)\n",
    "\n",
    "del word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116886"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.13964844, -0.00616455,  0.21484375,  0.07275391, -0.16113281,\n",
       "        0.07568359,  0.16796875, -0.20117188,  0.12597656,  0.00915527,\n",
       "        0.05249023, -0.15136719, -0.02758789,  0.04199219, -0.234375  ,\n",
       "        0.13867188, -0.02600098,  0.07910156,  0.02746582, -0.13085938,\n",
       "       -0.02478027,  0.10009766, -0.07910156, -0.07714844,  0.03759766,\n",
       "        0.16894531,  0.05371094, -0.05200195,  0.14453125, -0.04370117,\n",
       "       -0.12597656,  0.06884766, -0.10595703, -0.14550781, -0.00331116,\n",
       "        0.01367188,  0.13964844,  0.01660156,  0.03417969,  0.16113281,\n",
       "       -0.01080322,  0.06689453,  0.06835938, -0.15136719, -0.16894531,\n",
       "        0.03295898, -0.06884766,  0.06787109, -0.07373047,  0.08300781,\n",
       "        0.05761719,  0.14550781, -0.11865234, -0.13671875,  0.12402344,\n",
       "        0.04296875, -0.11962891, -0.08154297,  0.06494141, -0.05639648,\n",
       "       -0.04394531,  0.1484375 , -0.07714844,  0.04614258, -0.02624512,\n",
       "       -0.06591797,  0.04980469,  0.08886719, -0.01647949, -0.02294922,\n",
       "        0.10546875,  0.04199219,  0.11035156, -0.08251953, -0.13574219,\n",
       "       -0.07324219,  0.1015625 ,  0.05371094, -0.07275391,  0.08496094,\n",
       "       -0.04443359, -0.078125  ,  0.08398438, -0.00613403, -0.20898438,\n",
       "       -0.25      ,  0.00485229,  0.22363281,  0.01550293,  0.04223633,\n",
       "        0.07861328,  0.203125  , -0.25195312,  0.01867676,  0.03564453,\n",
       "       -0.09863281,  0.01745605,  0.12597656, -0.04589844, -0.10253906,\n",
       "       -0.10742188, -0.00558472,  0.05517578, -0.10791016, -0.1015625 ,\n",
       "        0.0222168 , -0.07958984,  0.04833984, -0.06201172, -0.11132812,\n",
       "        0.16210938, -0.09716797, -0.03222656,  0.08056641,  0.21386719,\n",
       "       -0.03759766,  0.06542969, -0.15527344,  0.00300598, -0.04907227,\n",
       "       -0.23730469,  0.13378906,  0.10253906,  0.07568359,  0.01330566,\n",
       "       -0.02770996, -0.27929688,  0.03112793,  0.00092316, -0.10107422,\n",
       "       -0.23730469, -0.21484375, -0.08496094, -0.16894531,  0.04370117,\n",
       "       -0.20996094,  0.00100708,  0.07617188, -0.03198242,  0.14160156,\n",
       "        0.15820312, -0.01275635,  0.04150391, -0.03393555,  0.12011719,\n",
       "       -0.08789062, -0.03735352, -0.16503906, -0.14257812, -0.05200195,\n",
       "        0.06542969,  0.22070312, -0.34570312,  0.10400391,  0.05053711,\n",
       "       -0.02368164, -0.13671875, -0.13476562,  0.09863281,  0.06689453,\n",
       "       -0.07666016,  0.20214844, -0.01806641, -0.06201172,  0.00402832,\n",
       "       -0.04174805,  0.06835938, -0.04882812,  0.12890625,  0.14941406,\n",
       "       -0.07763672,  0.09179688,  0.03686523, -0.08789062, -0.01721191,\n",
       "        0.15625   ,  0.16210938, -0.11328125, -0.00830078, -0.11962891,\n",
       "       -0.16601562, -0.12792969,  0.03759766, -0.16601562,  0.10449219,\n",
       "       -0.01220703, -0.01940918,  0.10009766,  0.0098877 ,  0.05957031,\n",
       "        0.17285156,  0.1484375 ,  0.21191406, -0.06835938, -0.04443359,\n",
       "       -0.12158203,  0.03088379,  0.02392578, -0.05297852, -0.09912109,\n",
       "       -0.00375366,  0.15625   , -0.06884766,  0.10205078,  0.00448608,\n",
       "        0.05053711, -0.11035156, -0.15332031,  0.03808594, -0.05249023,\n",
       "        0.01226807,  0.08935547,  0.06005859, -0.08007812, -0.24902344,\n",
       "       -0.01953125,  0.25390625,  0.00915527, -0.04345703,  0.0612793 ,\n",
       "       -0.06884766,  0.1015625 , -0.09326172, -0.07763672,  0.15625   ,\n",
       "       -0.10546875,  0.0625    ,  0.13574219, -0.06982422,  0.12792969,\n",
       "        0.05957031, -0.14550781,  0.08251953, -0.12792969,  0.14648438,\n",
       "       -0.15332031, -0.01708984, -0.01672363,  0.07958984,  0.01794434,\n",
       "        0.04199219, -0.12353516,  0.03320312, -0.11083984, -0.09716797,\n",
       "       -0.07568359,  0.14453125, -0.10351562,  0.05566406,  0.03369141,\n",
       "        0.01422119,  0.17382812,  0.10595703,  0.03930664,  0.27539062,\n",
       "       -0.14453125,  0.01672363,  0.03369141, -0.06542969, -0.1640625 ,\n",
       "        0.00909424, -0.07910156, -0.14453125,  0.03979492, -0.05761719,\n",
       "        0.078125  ,  0.12402344,  0.00671387, -0.19140625,  0.04248047,\n",
       "        0.02844238,  0.10351562,  0.33007812,  0.25      , -0.14160156,\n",
       "        0.04003906, -0.00201416, -0.12255859, -0.05297852,  0.02587891,\n",
       "        0.11669922, -0.07861328,  0.03320312,  0.14257812, -0.02856445,\n",
       "       -0.06494141,  0.03955078, -0.07421875, -0.07080078,  0.07714844,\n",
       "       -0.1015625 , -0.08300781, -0.11767578, -0.09619141, -0.203125  ,\n",
       "       -0.02490234,  0.19335938,  0.05712891,  0.09960938, -0.234375  ])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 3, 5, 6, 7, 8, 9, 7, 10]\n",
      "[1, 2, 3, 4, 3, 5, 6, 7, 8, 9]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "question1 = []\n",
    "question2 = []\n",
    "is_duplicate = []\n",
    "for index,row in df.iterrows():\n",
    "    print(row['question1'])\n",
    "    print(row['question2'])\n",
    "    print(row['is_duplicate'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191\n"
     ]
    }
   ],
   "source": [
    "maxlen = max(df['question1'].map(lambda x: len(x)).max(),df['question2'].map(lambda x:len(x)).max())\n",
    "print(maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of question1 data tensor: (404290, 100)\n",
      "Shape of question2 data tensor: (404290, 100)\n",
      "Shape of label tensor: (404290,)\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = 100\n",
    "q1_data = pad_sequences(df['question1'], maxlen=MAX_SEQUENCE_LENGTH)\n",
    "q2_data = pad_sequences(df['question2'], maxlen=MAX_SEQUENCE_LENGTH)\n",
    "labels = np.array(df['is_duplicate'], dtype=int)\n",
    "print('Shape of question1 data tensor:', q1_data.shape)\n",
    "print('Shape of question2 data tensor:', q2_data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  1,  2,  3,  4,  3,  5,  6,  7,  8,  9,  7, 10])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_TRAINING_DATA_FILE = 'q1_train.npy'\n",
    "Q2_TRAINING_DATA_FILE = 'q2_train.npy'\n",
    "LABEL_TRAINING_DATA_FILE = 'label_train.npy'\n",
    "WORD_EMBEDDING_MATRIX_FILE = 'word_embedding_matrix.npy'\n",
    "\n",
    "np.save(open(Q1_TRAINING_DATA_FILE, 'wb'), q1_data)\n",
    "np.save(open(Q2_TRAINING_DATA_FILE, 'wb'), q2_data)\n",
    "np.save(open(LABEL_TRAINING_DATA_FILE, 'wb'), labels)\n",
    "np.save(open(WORD_EMBEDDING_MATRIX_FILE, 'wb'), embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_matrix = np.load(open(WORD_EMBEDDING_MATRIX_FILE, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tensorflowenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
